ğŸ§¬ A Multilayer Classification Framework for Skin Disease Detection on SkinBench (v2)

SkinBench-v2 delivers a three-level (multilayer) classification pipeline for skin disease recognition:

L1 (Binary): Normal vs. Disease

L2 (Coarse multi-class): 8 disease super-classes

ALL9 (Fine multi-class): 9 classes (Normal + 8 diseases)

The repo includes trained evaluation utilities, figures (confusion matrices, ROC/PR curves, reliability diagrams), and tabular outputs. This branch documents reproducible evaluation and a Streamlit demo using the best models you trained.

ğŸ“‚ Repository Structure (v2) SkinBench/ â”œâ”€ data_raw/ # train/val/test//* â”œâ”€ eval_tools/ â”‚ â”œâ”€ run_all_evals.py # unified evaluation entrypoint â”‚ â”œâ”€ roc_pr_curves.py # plotting ROC & PR â”‚ â””â”€ ... â”œâ”€ models/ # model definitions (resnet50, densenet121, ...) â”œâ”€ runs/ â”‚ â”œâ”€ ALL9/ # fine 9-class results â”‚ â”œâ”€ L1/ # binary results â”‚ â”œâ”€ L2/ # 8-class results â”‚ â”œâ”€ SUBCLASS/ # (optional) subclass heads â”‚ â”œâ”€ figures/ # ğŸ” all plots live here (GitHub auto-renders) â”‚ â””â”€ tables/ # ğŸ“Š all CSVs (confusions, predictions, comparison) â”œâ”€ app.py # Streamlit demo â”œâ”€ README.md # this file â””â”€ .gitignore # ignore checkpoints & raw data

Important: Only relative paths are used below (e.g., runs/figures/confusion_ALL9_vit_resnet.png). Once you push to GitHub on v2, the images and tables render automatically.

ğŸ§ª Dataset Layout

Place your dataset under data_raw/ with the standard ImageFolder layout:

data_raw/ â”œâ”€ train/ â”‚ â”œâ”€ Acne/ Bacterial Infections/ Eczema/ Fungal Infections/ Normal/ â”‚ â”œâ”€ Pigmentation Disorders/ Pox/ Psoriasis/ Scabies/ â”œâ”€ val/ â”‚ â””â”€ (same 9 subfolders) â””â”€ test/ â””â”€ (same 9 subfolders)

ğŸ–¥ï¸ Environment

(conda recommended)
conda create -n torch_gpu python=3.10 -y conda activate torch_gpu pip install -r requirements.txt # create if not present; include torch/torchvision, scikit-learn, matplotlib, pandas, streamlit, etc.

ğŸš€ Training (step-by-step)

You already have trained checkpoints under runs///best.pt. If you want to retrain, run your projectâ€™s training entrypoint per phase/model (adapt the command to your script names):

Example commands (adapt to your train script/args):
ALL9 (9-class)
python -m models.train --phase ALL9 --model mobilenetv3 --data_dir data_raw --epochs 50 --out runs/ALL9/mobilenetv3

python -m models.train --phase ALL9 --model vit_resnet --data_dir data_raw --epochs 50 --out runs/ALL9/vit_resnet

python -m models.train --phase ALL9 --model swin_densenet --data_dir data_raw --epochs 50 --out runs/ALL9/swin_densenet

python -m models.train --phase ALL9 --model efficientnet --data_dir data_raw --epochs 50 --out runs/ALL9/efficientnet

python -m models.train --phase ALL9 --model vgg16 --data_dir data_raw --epochs 50 --out runs/ALL9/vgg16

python -m models.train --phase ALL9 --model vgg19 --data_dir data_raw --epochs 50 --out runs/ALL9/vgg19

(cnn baseline likewise)
L1 (binary: Normal vs Disease)
python -m models.train --phase L1 --model resnet50 --data_dir data_raw --epochs 30 --out runs/L1/resnet50

L2 (8-class diseases only)
python -m models.train --phase L2 --model resnet50 --data_dir data_raw --epochs 40 --out runs/L2/resnet50

python -m models.train --phase L2 --model densenet121 --data_dir data_raw --epochs 40 --out runs/L2/densenet121

Tip: Keep checkpoint filenames as runs///best.pt so the evaluator auto-discovers them.

ğŸ“ˆ Reproducible Evaluation

Run everything at once python -m eval_tools.run_all_evals --data_dir data_raw --phases ALL9 L1 L2 --models resnet50 densenet121 mobilenetv3 cnn vit_resnet swin_densenet efficientnet vgg16 vgg19
Outputs:

Figures â†’ runs/figures/*.png

Tables â†’ runs/tables/*.csv

Comparison table â†’ runs/tables/comparison_all_models.csv

Notable notes
Binary ROC/PR on L1: the evaluator expects multi-class probabilities for OVR plots; L1 uses binary heads. The script now skips OVR curves for L1 to avoid IndexError and uses binary ROC/PR instead.

Your earlier issues with RoutedFolder were resolved by passing the correct constructor args; evaluator now builds loaders internally.

ğŸ§ª Results (your reported metrics) ALL9 (9 classes) â€” Test set Model Accuracy Macro-F1 ViT-ResNet 0.9843 0.9836 Swin-DenseNet 0.9843 0.9839 EfficientNet 0.9833 0.9827 MobileNetV3 0.9815 0.9808 VGG16 0.9721 0.9713 VGG19 0.9667 0.9668 CNN baseline 0.6389 0.6220 ResNet50 (no ALL9 checkpoint) â€“ DenseNet121 (no ALL9 checkpoint) â€“

Key plots (auto-rendered on GitHub):

Confusion matrices runs/figures/confusion_ALL9_vit_resnet.png runs/figures/confusion_ALL9_swin_densenet.png runs/figures/confusion_ALL9_efficientnet.png runs/figures/confusion_ALL9_mobilenetv3.png runs/figures/confusion_ALL9_vgg16.png runs/figures/confusion_ALL9_vgg19.png runs/figures/confusion_ALL9_cnn.png

ROC (one-vs-rest): runs/figures/roc_ovr_ALL9_vit_resnet.png runs/figures/roc_ovr_ALL9_swin_densenet.png runs/figures/roc_ovr_ALL9_efficientnet.png runs/figures/roc_ovr_ALL9_mobilenetv3.png runs/figures/roc_ovr_ALL9_vgg16.png runs/figures/roc_ovr_ALL9_vgg19.png runs/figures/roc_ovr_ALL9_cnn.png

PR (one-vs-rest): runs/figures/pr_ovr_ALL9_vit_resnet.png runs/figures/pr_ovr_ALL9_swin_densenet.png runs/figures/pr_ovr_ALL9_efficientnet.png runs/figures/pr_ovr_ALL9_mobilenetv3.png runs/figures/pr_ovr_ALL9_vgg16.png runs/figures/pr_ovr_ALL9_vgg19.png runs/figures/pr_ovr_ALL9_cnn.png

Reliability diagrams: runs/figures/reliability_ALL9_vit_resnet.png runs/figures/reliability_ALL9_swin_densenet.png runs/figures/reliability_ALL9_efficientnet.png runs/figures/reliability_ALL9_mobilenetv3.png runs/figures/reliability_ALL9_vgg16.png runs/figures/reliability_ALL9_vgg19.png runs/figures/reliability_ALL9_cnn.png

L1 (Binary: Normal vs Disease) â€” Test set Model Accuracy Macro-F1 ResNet50 0.9980 0.9959

Plots: runs/figures/confusion_L1_resnet50.png runs/figures/roc_binary_L1_resnet50.png runs/figures/pr_binary_L1_resnet50.png runs/figures/reliability_L1_resnet50.png

L2 (8 diseases) â€” Test set Model Accuracy Macro-F1 DenseNet121 0.9853 0.9849 ResNet50 0.9827 0.9824

Plots: runs/figures/confusion_L2_densenet121.png runs/figures/confusion_L2_resnet50.png runs/figures/roc_ovr_L2_densenet121.png runs/figures/roc_ovr_L2_resnet50.png runs/figures/pr_ovr_L2_densenet121.png runs/figures/pr_ovr_L2_resnet50.png runs/figures/reliability_L2_densenet121.png runs/figures/reliability_L2_resnet50.png

CSV artifacts (render on GitHub)

Model comparison: runs/tables/comparison_all_models.csv

Per-model confusion tables (CSV): runs/tables/confusion_ALL9_vit_resnet.csv, ..._swin_densenet.csv, ..._efficientnet.csv, ..._mobilenetv3.csv, ..._vgg16.csv, ..._vgg19.csv, ..._cnn.csv runs/tables/confusion_L1_resnet50.csv, runs/tables/confusion_L2_resnet50.csv, runs/tables/confusion_L2_densenet121.csv

Predictions (CSV per model): runs/tables/pred_ALL9_vit_resnet.csv, ..._swin_densenet.csv, ..._efficientnet.csv, ..._mobilenetv3.csv, ..._vgg16.csv, ..._vgg19.csv, ..._cnn.csv runs/tables/pred_L1_resnet50.csv, runs/tables/pred_L2_resnet50.csv, runs/tables/pred_L2_densenet121.csv

ğŸŒ Streamlit Demo streamlit run app.py

Features:

Upload an image â†’ L1 â†’ L2 â†’ ALL9 cascade prediction

Uses your best checkpoints from runs///best.pt

Supports subclass prediction hooks (optional SUBCLASS/ heads)

If you see a Missing key(s) in state_dict error, it means the checkpoint was trained with a different head/backbone name. Re-export your model with the same class names and module keys used in models/*.py for inference.

ğŸ”’ Keeping the repo clean (no heavy files)

Add to .gitignore (already recommended):

checkpoints
runs//best.pt runs//best.pth runs//last.pt runs//last.pth runs//checkpoints/ models//best*.pt models/**/best*.pth

raw data
data_raw/

python cache
pycache/ *.pyc *.pyo

If you accidentally committed large checkpoints:

git rm --cached -r runs models git commit -m "remove tracked checkpoints" git push origin v2

ğŸ§© Reproducing exactly these plots

All the images shown above are already produced under runs/figures/. To regenerate them after retraining, simply re-run:

python -m eval_tools.run_all_evals --data_dir data_raw --phases ALL9 L1 L2 --models resnet50 densenet121 mobilenetv3 cnn vit_resnet swin_densenet efficientnet vgg16 vgg19

ğŸ“œ License

This repository is released under the MIT License. See LICENSE for details.

ğŸ™Œ Acknowledgements

Thanks to all open-source authors of PyTorch, Torchvision, scikit-learn, Matplotlib, and the SkinBench dataset contributors. Your evaluation plots and tables (runs/figures, runs/tables) make the results fully auditable on GitHub.
